---
sidebar_position: 4
---

# Developing a workflow

While it's nice to imagine that you'll be able to collect quality data on the first pass, crowdsourcing can be a bit more trial-and-error. This guide focuses on setting up a good workflow, and extending your run-script to support additional functionality. We'll work through a common workflow for launching a task, checking results, evaluating, and re-running.

## Proper use of `task_name`

TODO - describe good ways to use the `mephisto.blueprint.task_name` attribute.

## Setting up automated evaluation

TODO - show simple use of registering post-run evaluations

## Multi-purpose run scripts

TODO - show how to use Hydra arguments to make separate `qualifying` and `qualified` task pools.

## Using the existing review workflow

TODO - show how the existing review workflow could be used

## Automated review workflows

TODO - describe how one would extend the review workflow

